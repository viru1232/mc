# ðŸ“± SMS Spam Filtering using Naive Bayes & Logistic Regression
# Dataset: http://archive.ics.uci.edu/ml/datasets/sms+spam+collection

# -----------------------------------------------------------
# Step 1: Import Libraries
# -----------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB, BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import warnings
warnings.filterwarnings("ignore")
%matplotlib inline

# -----------------------------------------------------------
# Step 2: Load Dataset
# -----------------------------------------------------------
# The dataset is a single text file, each line formatted as:  "label<TAB>message"
# Example: "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet..."
data = pd.read_csv("SMSSpamCollection", sep='\t', header=None, names=['label', 'message'])
print("Dataset Loaded Successfully!")
print(data.head())

# -----------------------------------------------------------
# Step 3: Data Preprocessing
# -----------------------------------------------------------
# Encode labels: ham=0, spam=1
le = LabelEncoder()
data['label_num'] = le.fit_transform(data['label'])

# Display dataset info
print("\nData Information:")
print(data.info())
print("\nLabel Distribution:\n", data['label'].value_counts())

# Basic text cleaning (optional)
data['message'] = data['message'].str.lower()

# -----------------------------------------------------------
# Step 4: Feature Extraction (Text to Numeric)
# -----------------------------------------------------------
# Convert text messages into TF-IDF features
tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
X = tfidf.fit_transform(data['message'])
y = data['label_num']

print("\nFeature Matrix Shape:", X.shape)

# -----------------------------------------------------------
# Step 5: Train-Test Split
# -----------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("\nTraining Samples:", X_train.shape[0])
print("Testing Samples:", X_test.shape[0])

# -----------------------------------------------------------
# Step 6: Apply Machine Learning Algorithms
# -----------------------------------------------------------
# --- Model 1: Multinomial Naive Bayes ---
mnb = MultinomialNB()
mnb.fit(X_train, y_train)
y_pred_mnb = mnb.predict(X_test)

# --- Model 2: Logistic Regression ---
lr = LogisticRegression(max_iter=500)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# -----------------------------------------------------------
# Step 7: Evaluate Models
# -----------------------------------------------------------
def evaluate_model(name, y_true, y_pred):
    print(f"\nðŸ“Š Model: {name}")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Classification Report:\n", classification_report(y_true, y_pred))

evaluate_model("Multinomial Naive Bayes", y_test, y_pred_mnb)
evaluate_model("Logistic Regression", y_test, y_pred_lr)

# -----------------------------------------------------------
# Step 8: Cross-Validation
# -----------------------------------------------------------
cv_scores_mnb = cross_val_score(mnb, X, y, cv=5, scoring='accuracy')
cv_scores_lr = cross_val_score(lr, X, y, cv=5, scoring='accuracy')

print("\nðŸ“ˆ Cross-Validation Results:")
print(f"Naive Bayes Mean Accuracy: {cv_scores_mnb.mean():.4f}")
print(f"Logistic Regression Mean Accuracy: {cv_scores_lr.mean():.4f}")

# -----------------------------------------------------------
# Step 9: Hyperparameter Tuning
# -----------------------------------------------------------
# Naive Bayes (alpha tuning)
param_grid_nb = {'alpha': [0.1, 0.5, 1.0, 1.5, 2.0]}
grid_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring='accuracy')
grid_nb.fit(X_train, y_train)

print("\nBest Parameters for Naive Bayes:", grid_nb.best_params_)
print("Best CV Accuracy:", grid_nb.best_score_)

# Logistic Regression (C tuning)
param_grid_lr = {'C': [0.1, 0.5, 1, 5, 10]}
grid_lr = GridSearchCV(LogisticRegression(max_iter=500), param_grid_lr, cv=5, scoring='accuracy')
grid_lr.fit(X_train, y_train)

print("\nBest Parameters for Logistic Regression:", grid_lr.best_params_)
print("Best CV Accuracy:", grid_lr.best_score_)

# -----------------------------------------------------------
# Step 10: Final Model Comparison
# -----------------------------------------------------------
models = pd.DataFrame({
    'Model': ['Multinomial Naive Bayes', 'Logistic Regression'],
    'Test Accuracy': [accuracy_score(y_test, y_pred_mnb), accuracy_score(y_test, y_pred_lr)],
    'CrossVal Accuracy': [cv_scores_mnb.mean(), cv_scores_lr.mean()]
})

print("\nðŸ“Š Model Comparison Summary:")
print(models)

# -----------------------------------------------------------
# Step 11: Visualization
# -----------------------------------------------------------
plt.figure(figsize=(7,5))
sns.barplot(x='Model', y='Test Accuracy', data=models, palette='coolwarm')
plt.title("Model Accuracy Comparison")
plt.ylim(0.9, 1.0)
plt.show()
